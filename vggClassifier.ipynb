{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cat Vs Dog using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for layer in model_vgg16_conv.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Loading and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 150, 150\n",
        "train_data_dir = 'cats-and-dogs/train'\n",
        "val_data_dir = 'cats-and-dogs/test'\n",
        "model_weights_file = 'vgg16-xfer-weights.h5'\n",
        "nb_train_samples = 4\n",
        "nb_val_samples = 4\n",
        "nb_epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(img_width, img_height, 3))\n",
        "output_vgg16_conv = model_vgg16_conv(input_layer)\n",
        "x = Flatten()(output_vgg16_conv)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_34 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15239170 (58.13 MB)\n",
            "Trainable params: 524482 (2.00 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation and Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1004 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=4, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
        "                                                        batch_size=4,class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 3.0150 - accuracy: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 2s 281ms/step - loss: 3.0150 - accuracy: 0.5000 - val_loss: 0.7341 - val_accuracy: 0.6000\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8351 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.8351 - accuracy: 0.6250\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9468 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 117ms/step - loss: 0.9468 - accuracy: 0.5625\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.4397 - accuracy: 0.8750\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.7487 - accuracy: 0.7500\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.5244 - accuracy: 0.7500\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.4960 - accuracy: 0.7500\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 119ms/step - loss: 0.2536 - accuracy: 0.9375\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 0.9659 - accuracy: 0.5625\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 123ms/step - loss: 0.4765 - accuracy: 0.8125\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 116ms/step - loss: 0.5673 - accuracy: 0.7500\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7184 - accuracy: 0.6875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.7184 - accuracy: 0.6875\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.7387 - accuracy: 0.6250\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.3309 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 1.3309 - accuracy: 0.2500\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 119ms/step - loss: 0.0853 - accuracy: 1.0000\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 0.3047 - accuracy: 0.8750\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 117ms/step - loss: 0.6714 - accuracy: 0.6250\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.3792 - accuracy: 0.8750\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8032 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.8032 - accuracy: 0.6250\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 125ms/step - loss: 0.9220 - accuracy: 0.6250\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.4274 - accuracy: 0.8125\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.6875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.6613 - accuracy: 0.6875\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.2945 - accuracy: 0.9375\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.6250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.5626 - accuracy: 0.6250\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.3189 - accuracy: 0.8750\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1164 - accuracy: 1.0000\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.3183 - accuracy: 0.8125\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.1645 - accuracy: 0.9375\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.6875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 118ms/step - loss: 0.9555 - accuracy: 0.6875\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.3570 - accuracy: 0.8750\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.5266 - accuracy: 0.8125\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.2376 - accuracy: 0.8750\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.1502 - accuracy: 0.9375\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 122ms/step - loss: 0.3492 - accuracy: 0.8125\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.6302 - accuracy: 0.8125\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.6875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 122ms/step - loss: 0.8646 - accuracy: 0.6875\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.6055 - accuracy: 0.8750\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 0.4886 - accuracy: 0.8125\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.5263 - accuracy: 0.8750\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "4/4 [==============================] - 1s 121ms/step - loss: 0.1465 - accuracy: 0.9375\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]\n",
        "\n",
        "history = model.fit_generator( train_generator, callbacks = callbacks, steps_per_epoch=nb_train_samples, \n",
        "                              epochs=40, validation_data=validation_generator, validation_steps=nb_val_samples)\n",
        "\n",
        "print('Training Completed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cat.57.jpg', 'cat.58.jpg', 'cat.60.jpg', 'cat.70.jpg', 'cat.76.jpg', 'cat.78.jpg', 'cat.93.jpg', 'cat.94.jpg', 'dog.492.jpg', 'dog.493.jpg', 'dog.494.jpg', 'dog.496.jpg', 'dog.514.jpg', 'dog.531.jpg', 'dog.614.jpg', 'dog.618.jpg']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 179ms/step\n",
            "actual: cat | prdicted: cat\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "actual: cat | prdicted: dog\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "actual: cat | prdicted: cat\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "actual: cat | prdicted: dog\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "actual: cat | prdicted: dog\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "actual: cat | prdicted: dog\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "actual: cat | prdicted: cat\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "actual: cat | prdicted: cat\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "actual: dog | prdicted: dog\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "actual: dog | prdicted: dog\n",
            "0.75\n"
          ]
        }
      ],
      "source": [
        "mypath = \"cats-and-dogs/valid/\"\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "label = ['cat','dog']\n",
        "print(onlyfiles)\n",
        "count=0\n",
        "total=len(onlyfiles)\n",
        "# predicting images\n",
        "dog_counter = 0 \n",
        "cat_counter  = 0\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(mypath+file, target_size=(150,150))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "   \n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    l=classes[0]\n",
        "    print(\"actual: \"+file[:3]+\" | prdicted: \"+label[list(l).index(max(l))])\n",
        "    if(file[:3]==label[list(l).index(max(l))]):\n",
        "        count+=1\n",
        "print(count/total)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finished"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
